{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Korean_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37JHcSIY-9yx"
      },
      "source": [
        "## Korean text preprocessing\n",
        "\n",
        "Korean Hate Speech Dataset (https://github.com/kocohub/korean-hate-speech)\n",
        "\n",
        "9,381 human-labeled comments in total\n",
        "\n",
        "7,896 training set, 471 validation set, and 974 test set\n",
        "\n",
        "Each comment is annotated on two aspects, the existence of social bias and hate speech, given that hate speech is closely related to bias.\n",
        "\n",
        "- hate speech classification: hate, offensive, none"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YauAt0JEMqy",
        "outputId": "84166b39-356d-4475-9d39-de2d8ff9dbd5"
      },
      "source": [
        "# download the hate speech dataset\n",
        "!git clone https://github.com/kocohub/korean-hate-speech.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'korean-hate-speech'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 112 (delta 4), reused 0 (delta 0), pack-reused 103\u001b[K\n",
            "Receiving objects: 100% (112/112), 93.18 MiB | 17.12 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "Checking out files: 100% (20/20), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWBHT07kFDgY"
      },
      "source": [
        "# read text files\n",
        "import pandas as pd\n",
        "train_data = pd.read_csv('korean-hate-speech/labeled/train.tsv', sep='\\t')\n",
        "test_data = pd.read_csv('korean-hate-speech/labeled/dev.tsv', sep='\\t')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EgxXW7EsGEvM",
        "outputId": "d9ef753d-4a22-4bd2-db5b-f9cdbb6fa1d4"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>contain_gender_bias</th>\n",
              "      <th>bias</th>\n",
              "      <th>hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n",
              "      <td>False</td>\n",
              "      <td>others</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n",
              "      <td>True</td>\n",
              "      <td>gender</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7891</th>\n",
              "      <td>힘내세요~ 응원합니다!!</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7892</th>\n",
              "      <td>힘내세요~~삼가 고인의 명복을 빕니다..</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7893</th>\n",
              "      <td>힘내세용 ^^ 항상 응원합니닷 ^^ !</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7894</th>\n",
              "      <td>힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7895</th>\n",
              "      <td>힘들면 관뒀어야지 그게 현명한거다</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7896 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               comments  ...  hate\n",
              "0     (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...  ...  hate\n",
              "1     ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...  ...  none\n",
              "2     ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...  ...  hate\n",
              "3                    1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데  ...  none\n",
              "4     1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...  ...  hate\n",
              "...                                                 ...  ...   ...\n",
              "7891                                      힘내세요~ 응원합니다!!  ...  none\n",
              "7892                             힘내세요~~삼가 고인의 명복을 빕니다..  ...  none\n",
              "7893                              힘내세용 ^^ 항상 응원합니닷 ^^ !  ...  none\n",
              "7894  힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...  ...  none\n",
              "7895                                 힘들면 관뒀어야지 그게 현명한거다  ...  none\n",
              "\n",
              "[7896 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "hZUI7y4WGAb6",
        "outputId": "ce4bac0f-a04a-4829-dd28-d771bcaf1ec0"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>contain_gender_bias</th>\n",
              "      <th>bias</th>\n",
              "      <th>hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>지현우 나쁜놈</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>설마 ㅈ 현정 작가 아니지??</td>\n",
              "      <td>True</td>\n",
              "      <td>gender</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>지현우 범죄 저지르지 않았나요?</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>여자인생 망칠 일 있나 ㅋㅋ</td>\n",
              "      <td>True</td>\n",
              "      <td>gender</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?</td>\n",
              "      <td>False</td>\n",
              "      <td>others</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...</td>\n",
              "      <td>True</td>\n",
              "      <td>gender</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...</td>\n",
              "      <td>True</td>\n",
              "      <td>gender</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>471 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              comments  ...       hate\n",
              "0                          송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.  ...       none\n",
              "1                                              지현우 나쁜놈  ...  offensive\n",
              "2           알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라  ...       hate\n",
              "3                                     설마 ㅈ 현정 작가 아니지??  ...       hate\n",
              "4    이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...  ...  offensive\n",
              "..                                                 ...  ...        ...\n",
              "466                                  지현우 범죄 저지르지 않았나요?  ...  offensive\n",
              "467                                    여자인생 망칠 일 있나 ㅋㅋ  ...       hate\n",
              "468            근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?  ...  offensive\n",
              "469  할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...  ...       hate\n",
              "470  남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...  ...       none\n",
              "\n",
              "[471 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouP5HquGQO5"
      },
      "source": [
        "- on-line, user-generated text data\n",
        "- informal stylistic properties: 이모티콘, 비속어, 특수문자, 띄어쓰기/철자 오류, 일반적으로 사용되지 않는 단어 등\n",
        "\n",
        "이러한 특성을 고려해, 텍스트를 torchtext/모델에 넣기 전 cleansing, tokenization 등을 적절히 수행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6efIEe1NEJJ"
      },
      "source": [
        "### 1. 문장 내 한자, 특수기호 제거\n",
        "\n",
        "hanja 라이브러리, 정규표현식 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8YAon8YNUvE",
        "outputId": "209dafdf-35e9-441b-c806-561591182621"
      },
      "source": [
        "import re\n",
        "!pip install hanja\n",
        "import hanja"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hanja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/97/ce51b5c771e7c9a673568232125e587cbc378ff1dd13057f237bedcd71e8/hanja-0.13.3.tar.gz (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 3.8MB/s \n",
            "\u001b[?25hCollecting pyyaml==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 18.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from hanja) (3.6.4)\n",
            "Collecting pytest-cov\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/84/576b071aef9ac9301e5c0ff35d117e12db50b87da6f12e745e9c5f745cc2/pytest_cov-2.12.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: coveralls in /usr/local/lib/python3.7/dist-packages (from hanja) (0.5)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (8.7.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (21.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (57.0.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.10.0)\n",
            "Collecting coverage>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/e0/fc9f7bd9b84e6b41d0aad1a113e36714aac0c0a9b307aca5f9af443bc50f/coverage-5.5-cp37-cp37m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 32.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pytest-cov->hanja) (0.10.2)\n",
            "Requirement already satisfied: requests>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from coveralls->hanja) (2.23.0)\n",
            "Requirement already satisfied: docopt>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from coveralls->hanja) (0.6.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (2020.12.5)\n",
            "Building wheels for collected packages: hanja, pyyaml\n",
            "  Building wheel for hanja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hanja: filename=hanja-0.13.3-cp37-none-any.whl size=128426 sha256=cbcdbbb0d09f745cdb41ebc1ed65895f790ccdbd4c8dbf90eac338ae6b5a552f\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/fc/c9/b7e7cb5c86935a1a99e2ad07f763728f8f17560e7b815a4b27\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp37-cp37m-linux_x86_64.whl size=44117 sha256=5379d6dab8d175ffe614b7585e9d540b32604fd05747c9435adeb41d4d788792\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built hanja pyyaml\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement coverage==3.7.1, but you'll have coverage 5.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: coveralls 0.5 has requirement coverage<3.999,>=3.6, but you'll have coverage 5.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytest-cov 2.12.1 has requirement pytest>=4.6, but you'll have pytest 3.6.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyyaml, coverage, pytest-cov, hanja\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: coverage 3.7.1\n",
            "    Uninstalling coverage-3.7.1:\n",
            "      Successfully uninstalled coverage-3.7.1\n",
            "Successfully installed coverage-5.5 hanja-0.13.3 pytest-cov-2.12.1 pyyaml-5.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lRyyuvgOAU-",
        "outputId": "e856086f-fe98-419b-d81b-a36fa43069b4"
      },
      "source": [
        "# 문장 내 한자 제거\n",
        "\n",
        "sent = '이건진짜좋은映畫ㅋㅋ 라라랜드진짜재밌는영화!!!'\n",
        "\n",
        "# 한자에 해당하는 유니코드 범위 검색\n",
        "if re.search(\"[\\u2E80-\\u2FD5\\u3190-\\u319f\\u3400-\\u4DBF\\u4E00-\\u9FCC\\uF900-\\uFAAD]\", sent) is not None:\n",
        "  # 한자를 한글로 변환\n",
        "  sent_nohanja = hanja.translate(sent, 'substitution')\n",
        "\n",
        "print(sent_nohanja)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "이건진짜좋은영화ㅋㅋ 라라랜드진짜재밌는영화!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyrBnwXeOu95",
        "outputId": "865e952e-c377-4c2b-e37c-3872522f82c1"
      },
      "source": [
        "# 문장 내 특수기호 제거\n",
        "    \n",
        "sent = (r'\\[[^\\]]+\\]|\\([^\\)]+\\)|\\<[^\\>]+\\>', '', str(sent_nohanja))\n",
        "sent = re.sub(\"[.,!?||]\", \" \", str(sent))\n",
        "sent = re.sub(r'[^가-힣|\\s]', '', str(sent))\n",
        "sent = re.sub(r'\\s+', ' ', str(sent)) \n",
        "\n",
        "sent = sent.strip()\n",
        "\n",
        "print(sent)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "이건진짜좋은영화 라라랜드진짜재밌는영화\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Possible set union at position 5\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kANfQZsJ4TO"
      },
      "source": [
        "### 2. 띄어쓰기 오류 수정\n",
        "\n",
        "자동화된 방식 시도\n",
        "\n",
        "#### 2-1. soyspacing (https://github.com/lovit/soyspacing)\n",
        "\n",
        "말뭉치를 가지고 직접 모델을 학습해야 함 (제공되는 모델 없음)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m7jfFz6GPAg",
        "outputId": "71bf34e9-929f-48b6-90cb-e4b230f2e73f"
      },
      "source": [
        "!pip install soyspacing\n",
        "!git clone https://github.com/lovit/soyspacing.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soyspacing\n",
            "  Downloading https://files.pythonhosted.org/packages/66/30/2bcfe84f8cb41d0011ff6f430c47297e039054853ebc8906a8369594f776/soyspacing-1.0.17-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from soyspacing) (1.19.5)\n",
            "Installing collected packages: soyspacing\n",
            "Successfully installed soyspacing-1.0.17\n",
            "Cloning into 'soyspacing'...\n",
            "remote: Enumerating objects: 270, done.\u001b[K\n",
            "remote: Total 270 (delta 0), reused 0 (delta 0), pack-reused 270\u001b[K\n",
            "Receiving objects: 100% (270/270), 2.13 MiB | 16.65 MiB/s, done.\n",
            "Resolving deltas: 100% (130/130), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtQ1ho7oKMuq",
        "outputId": "89dcef36-f893-43bd-b226-4e7bf0114e2e"
      },
      "source": [
        "from soyspacing.countbase import CountSpace\n",
        "\n",
        "# sample corpus for training: 15,602 normalized movie reviews\n",
        "corpus_fname = 'soyspacing/demo_model/134963_norm.txt'\n",
        "# 말뭉치는 더 많은, 더 다양한 문장들로 구성되어 있을수록 더 도움이 될 것임\n",
        "\n",
        "model = CountSpace()\n",
        "model.train(corpus_fname) # 말뭉치를 이용해서 모델 학습"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all tags length = 694236 --> 57795, (num_doc = 15602)"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVej5-KEKhvD"
      },
      "source": [
        "# 학습한 모델 저장\n",
        "model.save_model('sample_model', json_format=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjXZ2lA1KsV1"
      },
      "source": [
        "# 학습한 모델 불러와서 사용\n",
        "model = CountSpace()\n",
        "model.load_model('sample_model', json_format=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DzfyO9VKyP1",
        "outputId": "7c4ff1e3-e3ed-4d07-f979-272f84241ebe"
      },
      "source": [
        "# 띄어쓰기 교정을 위한 parameters\n",
        "verbose=False\n",
        "mc = 10  # min_count\n",
        "ft = 0.3 # force_abs_threshold\n",
        "nt =-0.3 # nonspace_threshold\n",
        "st = 0.3 # space_threshold\n",
        "\n",
        "# 문장 띄어쓰기 교정 예시\n",
        "# sent: \"이건진짜좋은영화 라라랜드진짜좋은영화\"\n",
        "\n",
        "# with parameters\n",
        "sent_corrected, tags = model.correct(\n",
        "    doc=sent,\n",
        "    verbose=verbose,\n",
        "    force_abs_threshold=ft,\n",
        "    nonspace_threshold=nt,\n",
        "    space_threshold=st,\n",
        "    min_count=mc)\n",
        "\n",
        "print(sent_corrected)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "이건 진짜 좋은 영화 라라랜드진짜 재밌는 영화\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3h0jogdLMMa",
        "outputId": "7d0f3e50-e8c7-4bb6-c465-6ca19a2ca074"
      },
      "source": [
        "# 문장 띄어쓰기 교정 예시\n",
        "# without parameters: default value를 이용\n",
        "sent_corrected, tags = model.correct(sent)\n",
        "\n",
        "print(sent_corrected)\n",
        "print(tags)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "이건 진짜 좋은 영화 라라랜드진짜 재밌는 영화\n",
            "[0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, None, None, 1, 0, 0, 1, 0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyUD7hueLcey"
      },
      "source": [
        "특정 단어, 혹은 어절의 앞 뒤를 반드시 띄거나 붙여쓴다는 규칙이 있다면 이를 적용할 수 있음\n",
        "\n",
        "어절과 어절 앞, 뒤에 대한 띄어쓰기 태그가 포함되어 있는 텍스트 파일을 준비 -> 'rule'로서 작용하도록\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdv_ycxYLYdq",
        "outputId": "e8534766-fd5a-4839-9094-732d96bea82d"
      },
      "source": [
        "# rule example\n",
        "# 진짜 101: 진짜 라는 단어의 앞, 뒤는 반드시 띄어쓰기를 하고, 진과 짜 사이에는 반드시 붙여쓰기를 한다는 의미\n",
        "\n",
        "rule_f = open('rules.txt', 'w')\n",
        "rule_f.write(\"가령\t101\" + \"\\n\")\n",
        "rule_f.write(\"진짜\t101\" + \"\\n\")\n",
        "rule_f.write(\"가게는\t1001\" + \"\\n\")\n",
        "rule_f.write(\"가게로\t1001\" + \"\\n\")\n",
        "rule_f.write(\"가게야\t1001\" + \"\\n\")\n",
        "rule_f.close()\n",
        "\n",
        "print(open('rules.txt').readlines())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['가령\\t101\\n', '진짜\\t101\\n', '가게는\\t1001\\n', '가게로\\t1001\\n', '가게야\\t1001\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNb1nnMPMSEE",
        "outputId": "40e669d9-cf30-42c3-a228-e852c207d54b"
      },
      "source": [
        "from soyspacing.countbase import RuleDict\n",
        "\n",
        "rule_dict = RuleDict('rules.txt')\n",
        "sent_corrected, tags = model.correct(sent, rules=rule_dict)\n",
        "print(sent_corrected)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "이건 진짜 좋은 영화 라라랜드 진짜 재밌는 영화\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pumzsuvPjKyS"
      },
      "source": [
        "#### 2-2. PyKoSpacing (https://github.com/haven-jeon/PyKoSpacing)\n",
        "\n",
        "대용량 코퍼스를 학습하여 만들어진 띄어쓰기 딥 러닝 모델 제공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d03fAxm2iCJo",
        "outputId": "73f170d4-c5fd-436c-f875-59e6888824d3"
      },
      "source": [
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
            "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-683s4rpx\n",
            "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-683s4rpx\n",
            "Requirement already satisfied: tensorflow==2.5.0 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.5) (2.5.0)\n",
            "Requirement already satisfied: h5py==3.1.0 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.5) (3.1.0)\n",
            "Collecting argparse>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (3.12.4)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (0.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (2.5.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (2.5.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.34.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py==3.1.0->pykospacing==0.5) (1.5.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow==2.5.0->pykospacing==0.5) (57.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (1.30.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (0.6.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (0.4.8)\n",
            "Building wheels for collected packages: pykospacing\n",
            "  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykospacing: filename=pykospacing-0.5-cp37-none-any.whl size=2255825 sha256=3e294921b5ed921df6fd9bdf36837660f2a1e77d919ce33948541fdbceedd341\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x9n6865o/wheels/4d/45/58/e26cb2b7f6a063d234158c6fd1e5700f6e15b99d67154340ba\n",
            "Successfully built pykospacing\n",
            "Installing collected packages: argparse, pykospacing\n",
            "Successfully installed argparse-1.4.0 pykospacing-0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqAq1zzGiC71",
        "outputId": "1fb3d3be-7cc7-4de8-b254-a74553c71ce7"
      },
      "source": [
        "from pykospacing import Spacing\n",
        "spacing = Spacing()\n",
        "s = spacing('너무재밌었다그래서보는것을추천한다')\n",
        "print(s)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "너무 재밌었다 그래서 보는 것을 추천한다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2GpolzKjfV6"
      },
      "source": [
        "#### 2-3. PyHanSpell (https://github.com/ssut/py-hanspell)\n",
        "\n",
        "띄어쓰기 수정 + 맞춤법 수정 (네이버 한글 맞춤법 검사기 기반)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RbmbhtQjdpu",
        "outputId": "8ecf826c-d5a7-4220-ebb5-e79d360043bf"
      },
      "source": [
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-r942iqky\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-r942iqky\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2020.12.5)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-cp37-none-any.whl size=4871 sha256=71e04461e7c677930e84f0fc193b52dcf683e561dadb5c38304910660cb7616d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r7lyxoau/wheels/0a/25/d1/e5e96476dbb1c318cc26c992dd493394fe42b0c204b3e65588\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id2YK2ztj6JF",
        "outputId": "b14a53e3-8069-4596-9fd3-2b5ab014813f"
      },
      "source": [
        "from hanspell import spell_checker\n",
        "spelled_sent = spell_checker.check('외않됀데')\n",
        "print(spelled_sent)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checked(result=True, original='외않됀데', checked='왜 안 된대', errors=1, words=OrderedDict([('왜', 1), ('안', 1), ('된대', 1)]), time=0.7958540916442871)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UQS3ZGfUKk5"
      },
      "source": [
        "### 3. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jflhuCUvP8Dr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c222ac1f-669b-4f52-8e5e-23bcedecba40"
      },
      "source": [
        "!pip install konlpy\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 244kB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.3MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 34.3MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: beautifulsoup4, JPype1, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvLeL_hgc11X"
      },
      "source": [
        "koNLPy Okt (Twitter, Open Korean Text) tokenizer\n",
        "\n",
        "- 다른 형태소 분석기에 비해 단순한 품사 분류\n",
        "- 비교적 가볍고 빠른 분석\n",
        "- 사용자 사전 항목 추가 지원\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XczEmmmZY7Mz",
        "outputId": "a8923530-8b4e-45c3-9e24-f28a18d9ec10"
      },
      "source": [
        "print(okt.morphs('이건 진짜 재밌는 영화ㅋㅋㅋ 그래서 추천!!!'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['이건', '진짜', '재밌는', '영화', 'ㅋㅋㅋ', '그래서', '추천', '!!!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BBA6QO8ZFF_",
        "outputId": "619b1d2d-4dd9-489a-9242-6ba75131c3a9"
      },
      "source": [
        "print(okt.nouns('이건 진짜 재밌는 영화ㅋㅋㅋ 그래서 추천!!!'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['이건', '진짜', '영화', '추천']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9d9sLtxZcud",
        "outputId": "2d8a39e0-3dcb-4ba8-d2a8-e6920a84cc8a"
      },
      "source": [
        "# 특정 품사에 해당하는 토큰들만 선택하여 모델 인풋 텍스트를 구성하기도 함\n",
        "# 예: 명사(Noun), 동사(Verb), 형용사(Adjective), 부사(Adverb) 등\n",
        "\n",
        "adjectives = []\n",
        "\n",
        "for token in okt.pos('이건 진짜 재밌는 영화ㅋㅋㅋ 그래서 추천!!!'):\n",
        "  print(token)\n",
        "  if token[1] == 'Adjective':\n",
        "    adjectives.append(token[0])\n",
        "\n",
        "print('adjectives:', adjectives)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('이건', 'Noun')\n",
            "('진짜', 'Noun')\n",
            "('재밌는', 'Adjective')\n",
            "('영화', 'Noun')\n",
            "('ㅋㅋㅋ', 'KoreanParticle')\n",
            "('그래서', 'Adverb')\n",
            "('추천', 'Noun')\n",
            "('!!!', 'Punctuation')\n",
            "adjectives: ['재밌는']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9XnMWSVlf2i",
        "outputId": "57de187e-695e-44cc-f46d-2159f8db8ce7"
      },
      "source": [
        "# 모델 인풋 텍스트에서 stopwords를 제거하기도 함\n",
        "# stopwords: 유의미한 토큰만을 선별하기 위해 제거하는, 큰 의미가 없는 단어들\n",
        "\n",
        "# stopword list example\n",
        "# https://github.com/stopwords-iso/stopwords-ko\n",
        "!git clone https://github.com/stopwords-iso/stopwords-ko.git"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stopwords-ko'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Total 29 (delta 0), reused 0 (delta 0), pack-reused 29\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo_dAbhvliWj"
      },
      "source": [
        "import json\n",
        "with open('stopwords-ko/stopwords-ko.json') as json_file:\n",
        "  stopwords_json = json.load(json_file)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCvmWbv2meCp",
        "outputId": "265fa629-65ff-4e44-d2bd-df48f2047d62"
      },
      "source": [
        "print(stopwords_json)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['!', '\"', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '...', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ';', '<', '=', '>', '?', '@', '\\\\', '^', '_', '`', '|', '~', '·', '—', '——', '‘', '’', '“', '”', '…', '、', '。', '〈', '〉', '《', '》', '가', '가까스로', '가령', '각', '각각', '각자', '각종', '갖고말하자면', '같다', '같이', '개의치않고', '거니와', '거바', '거의', '것', '것과 같이', '것들', '게다가', '게우다', '겨우', '견지에서', '결과에 이르다', '결국', '결론을 낼 수 있다', '겸사겸사', '고려하면', '고로', '곧', '공동으로', '과', '과연', '관계가 있다', '관계없이', '관련이 있다', '관하여', '관한', '관해서는', '구', '구체적으로', '구토하다', '그', '그들', '그때', '그래', '그래도', '그래서', '그러나', '그러니', '그러니까', '그러면', '그러므로', '그러한즉', '그런 까닭에', '그런데', '그런즉', '그럼', '그럼에도 불구하고', '그렇게 함으로써', '그렇지', '그렇지 않다면', '그렇지 않으면', '그렇지만', '그렇지않으면', '그리고', '그리하여', '그만이다', '그에 따르는', '그위에', '그저', '그중에서', '그치지 않다', '근거로', '근거하여', '기대여', '기점으로', '기준으로', '기타', '까닭으로', '까악', '까지', '까지 미치다', '까지도', '꽈당', '끙끙', '끼익', '나', '나머지는', '남들', '남짓', '너', '너희', '너희들', '네', '넷', '년', '논하지 않다', '놀라다', '누가 알겠는가', '누구', '다른', '다른 방면으로', '다만', '다섯', '다소', '다수', '다시 말하자면', '다시말하면', '다음', '다음에', '다음으로', '단지', '답다', '당신', '당장', '대로 하다', '대하면', '대하여', '대해 말하자면', '대해서', '댕그', '더구나', '더군다나', '더라도', '더불어', '더욱더', '더욱이는', '도달하다', '도착하다', '동시에', '동안', '된바에야', '된이상', '두번째로', '둘', '둥둥', '뒤따라', '뒤이어', '든간에', '들', '등', '등등', '딩동', '따라', '따라서', '따위', '따지지 않다', '딱', '때', '때가 되어', '때문에', '또', '또한', '뚝뚝', '라 해도', '령', '로', '로 인하여', '로부터', '로써', '륙', '를', '마음대로', '마저', '마저도', '마치', '막론하고', '만 못하다', '만약', '만약에', '만은 아니다', '만이 아니다', '만일', '만큼', '말하자면', '말할것도 없고', '매', '매번', '메쓰겁다', '몇', '모', '모두', '무렵', '무릎쓰고', '무슨', '무엇', '무엇때문에', '물론', '및', '바꾸어말하면', '바꾸어말하자면', '바꾸어서 말하면', '바꾸어서 한다면', '바꿔 말하면', '바로', '바와같이', '밖에 안된다', '반대로', '반대로 말하자면', '반드시', '버금', '보는데서', '보다더', '보드득', '본대로', '봐', '봐라', '부류의 사람들', '부터', '불구하고', '불문하고', '붕붕', '비걱거리다', '비교적', '비길수 없다', '비로소', '비록', '비슷하다', '비추어 보아', '비하면', '뿐만 아니라', '뿐만아니라', '뿐이다', '삐걱', '삐걱거리다', '사', '삼', '상대적으로 말하자면', '생각한대로', '설령', '설마', '설사', '셋', '소생', '소인', '솨', '쉿', '습니까', '습니다', '시각', '시간', '시작하여', '시초에', '시키다', '실로', '심지어', '아', '아니', '아니나다를가', '아니라면', '아니면', '아니었다면', '아래윗', '아무거나', '아무도', '아야', '아울러', '아이', '아이고', '아이구', '아이야', '아이쿠', '아하', '아홉', '안 그러면', '않기 위하여', '않기 위해서', '알 수 있다', '알았어', '앗', '앞에서', '앞의것', '야', '약간', '양자', '어', '어기여차', '어느', '어느 년도', '어느것', '어느곳', '어느때', '어느쪽', '어느해', '어디', '어때', '어떠한', '어떤', '어떤것', '어떤것들', '어떻게', '어떻해', '어이', '어째서', '어쨋든', '어쩔수 없다', '어찌', '어찌됏든', '어찌됏어', '어찌하든지', '어찌하여', '언제', '언젠가', '얼마', '얼마 안 되는 것', '얼마간', '얼마나', '얼마든지', '얼마만큼', '얼마큼', '엉엉', '에', '에 가서', '에 달려 있다', '에 대해', '에 있다', '에 한하다', '에게', '에서', '여', '여기', '여덟', '여러분', '여보시오', '여부', '여섯', '여전히', '여차', '연관되다', '연이서', '영', '영차', '옆사람', '예', '예를 들면', '예를 들자면', '예컨대', '예하면', '오', '오로지', '오르다', '오자마자', '오직', '오호', '오히려', '와', '와 같은 사람들', '와르르', '와아', '왜', '왜냐하면', '외에도', '요만큼', '요만한 것', '요만한걸', '요컨대', '우르르', '우리', '우리들', '우선', '우에 종합한것과같이', '운운', '월', '위에서 서술한바와같이', '위하여', '위해서', '윙윙', '육', '으로', '으로 인하여', '으로서', '으로써', '을', '응', '응당', '의', '의거하여', '의지하여', '의해', '의해되다', '의해서', '이', '이 되다', '이 때문에', '이 밖에', '이 외에', '이 정도의', '이것', '이곳', '이때', '이라면', '이래', '이러이러하다', '이러한', '이런', '이럴정도로', '이렇게 많은 것', '이렇게되면', '이렇게말하자면', '이렇구나', '이로 인하여', '이르기까지', '이리하여', '이만큼', '이번', '이봐', '이상', '이어서', '이었다', '이와 같다', '이와 같은', '이와 반대로', '이와같다면', '이외에도', '이용하여', '이유만으로', '이젠', '이지만', '이쪽', '이천구', '이천육', '이천칠', '이천팔', '인 듯하다', '인젠', '일', '일것이다', '일곱', '일단', '일때', '일반적으로', '일지라도', '임에 틀림없다', '입각하여', '입장에서', '잇따라', '있다', '자', '자기', '자기집', '자마자', '자신', '잠깐', '잠시', '저', '저것', '저것만큼', '저기', '저쪽', '저희', '전부', '전자', '전후', '점에서 보아', '정도에 이르다', '제', '제각기', '제외하고', '조금', '조차', '조차도', '졸졸', '좀', '좋아', '좍좍', '주룩주룩', '주저하지 않고', '줄은 몰랏다', '줄은모른다', '중에서', '중의하나', '즈음하여', '즉', '즉시', '지든지', '지만', '지말고', '진짜로', '쪽으로', '차라리', '참', '참나', '첫번째로', '쳇', '총적으로', '총적으로 말하면', '총적으로 보면', '칠', '콸콸', '쾅쾅', '쿵', '타다', '타인', '탕탕', '토하다', '통하여', '툭', '퉤', '틈타', '팍', '팔', '퍽', '펄렁', '하', '하게될것이다', '하게하다', '하겠는가', '하고 있다', '하고있었다', '하곤하였다', '하구나', '하기 때문에', '하기 위하여', '하기는한데', '하기만 하면', '하기보다는', '하기에', '하나', '하느니', '하는 김에', '하는 편이 낫다', '하는것도', '하는것만 못하다', '하는것이 낫다', '하는바', '하더라도', '하도다', '하도록시키다', '하도록하다', '하든지', '하려고하다', '하마터면', '하면 할수록', '하면된다', '하면서', '하물며', '하여금', '하여야', '하자마자', '하지 않는다면', '하지 않도록', '하지마', '하지마라', '하지만', '하하', '한 까닭에', '한 이유는', '한 후', '한다면', '한다면 몰라도', '한데', '한마디', '한적이있다', '한켠으로는', '한항목', '할 따름이다', '할 생각이다', '할 줄 안다', '할 지경이다', '할 힘이 있다', '할때', '할만하다', '할망정', '할뿐', '할수있다', '할수있어', '할줄알다', '할지라도', '할지언정', '함께', '해도된다', '해도좋다', '해봐요', '해서는 안된다', '해야한다', '해요', '했어요', '향하다', '향하여', '향해서', '허', '허걱', '허허', '헉', '헉헉', '헐떡헐떡', '형식으로 쓰여', '혹시', '혹은', '혼자', '훨씬', '휘익', '휴', '흐흐', '흥', '힘입어', '︿', '！', '＃', '＄', '％', '＆', '（', '）', '＊', '＋', '，', '０', '１', '２', '３', '４', '５', '６', '７', '８', '９', '：', '；', '＜', '＞', '？', '＠', '［', '］', '｛', '｜', '｝', '～', '￥']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3kNoUaeaVc3",
        "outputId": "2108e1f2-46cc-4354-d4a2-bf3c41be1c88"
      },
      "source": [
        "sent_filtered = []\n",
        "\n",
        "for token in okt.morphs('이건 진짜 재밌는 영화ㅋㅋㅋ 그래서 추천!!!'):\n",
        "  if token in stopwords_json:\n",
        "    pass\n",
        "  else:\n",
        "    sent_filtered.append(token)\n",
        "\n",
        "print(' '.join(sent_filtered))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "이건 진짜 재밌는 영화 ㅋㅋㅋ 추천 !!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9YL7z_weYNR"
      },
      "source": [
        "### 위의 전처리 과정들을 함수로 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItpWYnTqec2A"
      },
      "source": [
        "def cleanse_sentence(sent): \n",
        "    \n",
        "    # 문장 내 한자 제거\n",
        "    if re.search(\"[\\u2E80-\\u2FD5\\u3190-\\u319f\\u3400-\\u4DBF\\u4E00-\\u9FCC\\uF900-\\uFAAD]\", sent) is not None:\n",
        "        sent = hanja.translate(sent, 'substitution')\n",
        "        \n",
        "    # 문장 내 특수기호 제거\n",
        "    sent = (r'\\[[^\\]]+\\]|\\([^\\)]+\\)|\\<[^\\>]+\\>', '', str(sent))\n",
        "    sent = re.sub(\"[.,!?||]\", \" \", str(sent))\n",
        "    sent = re.sub(r'[^가-힣|\\s]', '', str(sent))\n",
        "    sent = re.sub(r'\\s+', ' ', str(sent)) \n",
        "    \n",
        "    return sent.strip()\n",
        "\n",
        "\n",
        "# 문장 토큰화 함수\n",
        "def tokenizer(string):\n",
        "    okt = Okt()\n",
        "\n",
        "    # 위 함수를 적용하여 불필요한 한자, 특수기호 등 제거\n",
        "    string = cleanse_sentence(string)\n",
        "    # 미처 제거되지 못한 특수기호 마저 제거\n",
        "    string.replace(\"…\",\"\")\n",
        "    string.replace(\"ㆍ\",\"\")\n",
        "\n",
        "    # 띄어쓰기 오류 수정\n",
        "    # from pykospacing import Spacing\n",
        "    # spacing = Spacing()\n",
        "    string_corrected = spacing(string)\n",
        "\n",
        "    # 형태소 분석기를 적용하여 문장 토큰화\n",
        "    morphs = okt.morphs(string_corrected)\n",
        "\n",
        "    # 분석된 토큰들 중 stopwords에 포함되는 것을 제거\n",
        "    # stopword list: https://github.com/stopwords-iso/stopwords-ko/blob/master/stopwords-ko.json\n",
        "    morphs_filtered = []\n",
        "    for morph in morphs:\n",
        "      if morph not in stopwords_json:\n",
        "        morphs_filtered.append(morph)\n",
        "    \n",
        "    return morphs_filtered\n",
        "        "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS-ycyvEf4a-",
        "outputId": "dec5559d-a68d-4eb0-b293-54c39dfe5fb6"
      },
      "source": [
        "# raw text example\n",
        "for text in train_data['comments'][500:515]:\n",
        "  print(text)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "결국 했지만 몰랐다 인가요?!\n",
            "결국엔 양세종이나 장혁...둘중에 하난 죽거나 아님 둘다 살거나...뭐 이성계쪽은 다 죽겠지...그래도 역사는 못바꾸겠지...\n",
            "결국은 주말시간대에 20프로 실패했구나 역시 스브스는 평일시간대에 21프로 돌파한 김사부2가 최고네 김사부2는 초중반에 21프로 돌파중인데ㄷㄷㄷ 김사부2 한석규 대상 확정 ㄷㄷㄷ\n",
            "결론은 많이 먹어서..예요\n",
            "결론은 빠순이들이 문제라는거 아냐\n",
            "결백은 당신에게 안어울림 그냥 자백하고 반성하는 척이라도 해라\n",
            "결별관심없고, 그냥 한혜진 왜나오는지 모르겠음 화사가 차라리 백번 착해보이고 궁금함\n",
            "결헌식 꼭 하고 축하 받으세요\n",
            "결혼 가즈아~~~♡♡♡겉껍데기(외모+돈)을 좋아하는 사람들이 많은 이 세상에 마음이나 성격을 보고 사람을 선택할 줄 아는 눈을 가진 세아씨가 멋지고 부럽네요.\n",
            "결혼 많이해서 좋으시겟다\n",
            "결혼 못하는놈들 댓글보소 ㅋㅋㅋ\n",
            "결혼 잘 해서 행복한듯 보기가 좋내요.\n",
            "결혼 축하합니다~ 행복하세요\n",
            "결혼까지 생각했어 같은집 같은방에서 슬퍼도 bye bye bye~~~~#\n",
            "결혼까지는 아닌듯연애하다말듯여자가 너무아까운 나이자나\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0NcDk3xgJqk",
        "outputId": "95182fd4-7214-4bf3-fe3f-8067f100fc0d"
      },
      "source": [
        "# 전처리 함수 적용 예시\n",
        "for text in train_data['comments'][500:515]:\n",
        "  print(tokenizer(text))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['했지만', '몰랐다', '인가요']\n",
            "['엔', '양세종', '이나', '장혁', '중', '난', '죽거나', '아님', '다', '살거나', '뭐', '성계', '쪽', '은', '다', '죽겠지', '역사', '는', '못', '바꾸겠지']\n",
            "['은', '주말', '시간대', '프로', '실패했구나', '역시', '스브스', '는', '평일', '시간대', '프로', '돌파', '한', '김사', '부가', '최고', '김', '사부', '는', '초', '중반', '프로', '돌파', '중', '인데', '김', '사부', '한석규', '대상', '확정']\n",
            "['결론', '은', '많이', '먹어서', '예요']\n",
            "['결론', '은', '빠순이', '문제', '라는', '거', '아냐']\n",
            "['결백', '은', '안', '어울림', '그냥', '자백', '하고', '반성', '하는', '척', '이라도', '해', '라']\n",
            "['결별', '관심', '없고', '그냥', '한', '혜진', '나오는지', '모르겠음', '화사', '백', '번', '착해', '보이', '고', '궁금함']\n",
            "['결', '헌', '식', '꼭', '하고', '축하', '받으세요']\n",
            "['결혼', '즈', '겉', '껍데기', '외모', '돈', '좋아하는', '사람', '많은', '세상', '마음', '이나', '성격', '보고', '사람', '선택', '할', '줄', '아는', '눈', '가진', '세', '아씨', '멋지고', '부럽네요']\n",
            "['결혼', '많이', '해서', '좋으시겟다']\n",
            "['결혼', '못', '하는', '놈', '댓글', '보소']\n",
            "['결혼', '잘', '해서', '행복한', '듯', '보기', '좋내요']\n",
            "['결혼', '축하', '합니다', '행복하세요']\n",
            "['결혼', '생각', '했어', '같은', '집', '같은', '방', '슬퍼도']\n",
            "['결혼', '까지는', '아닌', '듯', '연애', '하다', '말듯', '여자', '너무', '아까운', '이자나']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFCePiTnfukR"
      },
      "source": [
        "## torchtext를 이용해 데이터 세팅하기\n",
        "\n",
        "### torchtext: PyTorch가 제공하는 텍스트 관련 기능들을 모은 라이브러리\n",
        "* from torchtext.legacy import data, datasets\n",
        "* from torchtext.vocab import Vectors 등\n",
        "* 파일 로드하기, 토큰화(tokenization), 사전(vocab) 구성, 단어->정수(integer) 인코딩, 단어 벡터 구성, 배치화(batching) 등\n",
        "* torchtext 내부 'data'에서 하위 메서드를 불러와서 사용할 것임 (TabularDataset, BucketIterator 등)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lmbsWqM_Rr_"
      },
      "source": [
        "import torch, torchtext\n",
        "# from torchtext import data, datasets\n",
        "from torchtext.legacy import data, datasets"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "b_79lnI_9aUR",
        "outputId": "1978587d-c1cd-4c55-b330-126a210b37e7"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>contain_gender_bias</th>\n",
              "      <th>bias</th>\n",
              "      <th>hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n",
              "      <td>False</td>\n",
              "      <td>others</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n",
              "      <td>True</td>\n",
              "      <td>gender</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7891</th>\n",
              "      <td>힘내세요~ 응원합니다!!</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7892</th>\n",
              "      <td>힘내세요~~삼가 고인의 명복을 빕니다..</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7893</th>\n",
              "      <td>힘내세용 ^^ 항상 응원합니닷 ^^ !</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7894</th>\n",
              "      <td>힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7895</th>\n",
              "      <td>힘들면 관뒀어야지 그게 현명한거다</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7896 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               comments  ...  hate\n",
              "0     (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...  ...  hate\n",
              "1     ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...  ...  none\n",
              "2     ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...  ...  hate\n",
              "3                    1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데  ...  none\n",
              "4     1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...  ...  hate\n",
              "...                                                 ...  ...   ...\n",
              "7891                                      힘내세요~ 응원합니다!!  ...  none\n",
              "7892                             힘내세요~~삼가 고인의 명복을 빕니다..  ...  none\n",
              "7893                              힘내세용 ^^ 항상 응원합니닷 ^^ !  ...  none\n",
              "7894  힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...  ...  none\n",
              "7895                                 힘들면 관뒀어야지 그게 현명한거다  ...  none\n",
              "\n",
              "[7896 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS8pQJ5Z9MhB"
      },
      "source": [
        "# torchtext 필드 선언\n",
        "# 필드: 데이터에 대해 앞으로 어떤 전처리를 할 것인지 정의하기 위한 도구\n",
        "TEXT = data.Field(preprocessing=tokenizer, include_lengths=True, batch_first=True, sequential=False)\n",
        "LABEL = data.LabelField(dtype=torch.long)\n",
        "\n",
        "data_fields = [(\"comments\", TEXT), (\"contain_gender_bias\", None), (\"bias\", None), (\"hate\", LABEL)]\n",
        "\n",
        "# 데이터 불러오기\n",
        "train_set, test_set = data.TabularDataset.splits(path ='korean-hate-speech/labeled', \n",
        "                                                   train='train.tsv',\n",
        "                                                   test='dev.tsv',\n",
        "                                                   format='tsv',\n",
        "                                                   fields=data_fields,\n",
        "                                                   skip_header=True\n",
        "                                                  )"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzxU-eYTVKSJ",
        "outputId": "8623c90e-519c-42d7-e699-d68f369faf66"
      },
      "source": [
        "print('NUMBER of TRAIN data:', len(train_set))\n",
        "print('NUMBER of TEST data:', len(test_set))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUMBER of TRAIN data: 7896\n",
            "NUMBER of TEST data: 471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nOn2tERVPsH",
        "outputId": "a50d519b-08ae-40b5-9f9a-bb113f12a3ad"
      },
      "source": [
        "print(vars(train_set.examples[1]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'comments': ['한국', '적', '인', '미인', '대표', '적', '인', '분', '너무나', '곱', '고', '아름다운', '모습', '모습', '뒤', '슬픔', '미', '처', '알', '지', '못', '했네요'], 'hate': 'none'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhCVSVe-9v4K"
      },
      "source": [
        "# 분류 모델에서 사용할 수 있는 형태로 변환\n",
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, test_iterator = data.BucketIterator.splits((train_set, test_set), \n",
        "                                                           sort_key=lambda x: len(x.comments),\n",
        "                                                          sort_within_batch=False,\n",
        "                                                           repeat=False,\n",
        "                                                          batch_size=BATCH_SIZE, \n",
        "                                                           device=device)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttsda8ERY_X_"
      },
      "source": [
        "iterator 내에서 batch를 이용해 model prediction을 얻고 model training, evaluation 등을 수행\n",
        "- 실제 모델에 적용하는 것은 한국어 뉴스기사 분류 실습에서 다룰 예정"
      ]
    }
  ]
}